{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde511a3",
   "metadata": {},
   "source": [
    "# Exercise 2 - RNA editing detection using sequencing data\n",
    "##  Giant fiber lobe (GFL) notebook\n",
    "### submit: David Gorelik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db49feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished imports\n"
     ]
    }
   ],
   "source": [
    "import PySAM as pysam #import pysam as the other version didn't \n",
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "print(\"Finished imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d270112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 6600-1BAB\n",
      "\n",
      " Directory of C:\\Users\\zbida\\OneDrive - Bar-Ilan University - Students\\Documents\\Documents_general\\Cloud\\Bar-Ilan\\courses\\Neurogenomics\\Untitled Folder\n",
      "\n",
      "05/03/2022  07:10 PM    <DIR>          .\n",
      "05/03/2022  07:10 PM    <DIR>          ..\n",
      "05/03/2022  12:02 PM    <DIR>          .ipynb_checkpoints\n",
      "05/03/2022  12:04 PM            61,178 Class_editing_analysis.ipynb\n",
      "05/03/2022  12:05 PM            60,749 Class_editing_analysis_gills.ipynb\n",
      "05/03/2022  07:10 PM             6,377 exe2_squid.ipynb\n",
      "05/03/2022  01:59 PM    <DIR>          GFL\n",
      "05/03/2022  11:56 PM    <DIR>          Gills\n",
      "05/03/2022  12:03 PM        23,089,234 pealeii.txt\n",
      "               4 File(s)     23,217,538 bytes\n",
      "               5 Dir(s)   4,803,829,760 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30160093",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>q1:</b> Read the transcriptome file, i.e. all the genes of the squid, and collect the open reading frame and the RNA sequence of each gene.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91fb20",
   "metadata": {},
   "source": [
    "First we daclare a helper class and then we collect the transcriptome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a48fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper class fpr the transcriptome file, contains multiple variables\n",
    "class Transcriptome_gene:\n",
    "    def __init__(self, name, orfStart, orfEnd, strand, GO, seq, seq_ORF = None):\n",
    "        self.name = name\n",
    "        self.orfStart = orfStart\n",
    "        self.orfEnd = orfEnd\n",
    "        self.strand = strand\n",
    "        self.GO = GO\n",
    "        self.seq = seq\n",
    "        self.seq_ORF = seq_ORF\n",
    "    \n",
    "path_squid_transcripts = \"pealeii.txt\" # the file located locally in the same dir as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5514c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to read the file using biopython, and then save each gene in dict \n",
    "dict_genes = {} #daclare dict\n",
    "with open(path_squid_transcripts) as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        # We will devide the description into it's arguments\n",
    "        list_items = ((record.description).split(\"\\t\"))\n",
    "        name = list_items[0]\n",
    "        orfStart = int(list_items[2])\n",
    "        orfEnd = int(list_items[4])\n",
    "        strand = list_items[6]\n",
    "        GO = list_items[7]\n",
    "        seq = record.seq #biopython seq\n",
    "        seq_ORF = seq[orfStart-1:orfEnd -1]\n",
    "        \n",
    "        # use the defined class and save each item.\n",
    "        gene_transcript = Transcriptome_gene(name = name, orfStart = orfStart, orfEnd = orfEnd, \n",
    "                                                strand = strand,GO = GO, seq = seq, seq_ORF = seq_ORF)\n",
    "        # Now we will save the final item in a dict with key \n",
    "        dict_genes[name] = gene_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eddf8e8",
   "metadata": {},
   "source": [
    "Now we will give an example to the usage of the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8df11c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our gene name are: comp132287_c0_seq3 We access the data as:\n",
      "AAAAATACAATAAAAAGAAAAAAATACAAAAATAACCCTAAACGGTTTCAGTTATTCAACACGATGGTCGAGGCACTATCAGCAGTCACAATTAACGGCACCCTGGCCCGTATGGGGCTCAACTTTACAGATGCTGACAAGGAGGGCGATGAGGCCGACCACGAAGCACATAGTCTGGACAGAAACATGGAACGCATTGTTGTGCCGATCTTATTTGGCGTTGCGTTCATTGTCGGTATTGTCGGGAATGGCACCCTCATCTATACAGTCTTGCGTAACCGAAAAATGAGAGTGGTCCCTAACATCTATATTGTAAGTCTATCTTGCGGCGACTTCTTACTCATACTCATTGCTGTACCCTTCAACGCCCTTATTTATATCTTACCGGAATGGCCGTTTGGAGAAATCATGTGTAAGGTCAACGAATACCTCCAAACTGTATCCCTAGGGGTTTCCGTATTTATGCTCACAGCTCTGAGCGCCGATCGGCATATTGCTATTGTGGACCCTATAGCTAAGCACAAATCAAGGCCCATCGTCCGCGCAGTCACCACAGCCGGCTGCTTGTGGCTAGTGGCTCTTTTGTTAGGCATACCGGATTTAAGTTCGTCGACCGTCATCCAGTTCTCACCCAACATCACCCTTGGATCTTACAAGGTTTGCATCTTATACCCGACCTCGGATTTCGGAGGGTACTTACCGCCGTGGTATTCGCAACTGATGGTCATGCTCAAGTTTTTCATCTTCTTCCTCGTGCCGCTGTTCATCATCGGCGCCTTCTACATCCTGATGGCGCGGATCCTCATCCTGAGCGCCAAACAGATCCCGGGCGATTCGAACGGGCGAGCGGCCTACCAGAAACAGATCGAGGCGCGCCTCAAGGTCGCCAAGGCGGTCCTGTCGTTCGTCGTCCTCTTCGTAATCTGCTGGCTACCCCGTCACATCTACCTGTTGTGCTACTACTACTACGACGGCGATTTCAACCAGTTCTGGCACATTTTCAAAGTGACTAGTTTCTGCCTCGCCTTCATCAACTCTTGCGTTAACCCGTTCGCGCTCTATTTCCTCAGCAACCAGTTTCGGAAGTATTACAACCGTTACTTGTTTTGCTGCTGTACAGGCAAACCGTACGAGTTCCTTCCCGGACCTGGATCATCGGTAATGTATAATTTTCGGAGCACAGTCAGGCAGCCCAGTTCAAGCGTTACTTATGTGCAGAACCAAACAACATG\n"
     ]
    }
   ],
   "source": [
    "for key_gene_name in dict_genes:\n",
    "    print (\"Our gene name are:\", key_gene_name, \"We access the data as:\")\n",
    "    print(dict_genes[key_gene_name].seq_ORF)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f46af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>q2:</b> Run over all the genes that are present in the transcriptome file. Print to file the name of the gene that is being examined\n",
    "    \n",
    "<b>q3:</b> For each gene, run over all the gene locations that are inside the open reading frame using pysam pileup. We are only looking for modifications inside the open reading frame, i.e. modifications in the untranslated regions should not be detected.\n",
    "    \n",
    "<b>q4:</b> For each location, you should examine all the reads that are uniquely mapped to that location (more accurately: reads that are uniquely mapped to that gene and the alignment contain that specific location). In addition, demand a quality score of 30 or above for the aligned read in that location.\n",
    "    \n",
    "<b> q5: </b> For each location, you should calculate how many counts (i.e. aligned reads that passed the criteria above) are there for each base: A, C, T, and G. Sort the counts for each base from the highest to the lowest. The highest will be treated as the ‘unmodified’ base, and the second highest will be treated as the ‘modified’ base. Say that A is the ‘unmodified’ base and G is the ‘modified’ base, the ‘modification’ is therefore AG (A-to-G).\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072623a",
   "metadata": {},
   "source": [
    "We first daclare our variables as requseted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f261ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code based and copied from the given notebook in the assigment\n",
    "\n",
    "### start of input\n",
    "minimum_qaulity_score=30 # quality score 30 corresponds to 1/1000 error rate, or 1e-3 sequencing error \n",
    "P=1e-3 #  propability of sequencing error given qaulity score of 30\n",
    "max_mapping_score=42 # the maximal mapping quality means unique alignment, with bowtie2 this number is 42\n",
    "p_cutoff=0.05 # the cutoff for significance, note that bonferroni correction is used below\n",
    "\n",
    "bam_file_to_read=\"GFL/aligned_RNAreads_sorted.bam\"\n",
    "output_file=\"GFL/editing_sites_spectrin.txt\"\n",
    "length_of_read=100\n",
    "total_orf_size=16607506\n",
    "\n",
    "counts_per_letter={} # initilize dictionary for counts per letter\n",
    "number_of_modifications={} # initilize dictionary for type of modification\n",
    "type_of_modifications=['AC','AG','AT','CA','CG','CT','GA','GC','GT','TA','TC','TG']\n",
    "for x in type_of_modifications:\n",
    "    number_of_modifications[x] = 0\n",
    "position_of_mismatch_inside_the_read=np.zeros(length_of_read) # initilize numpy array for position of mismatch in the read\n",
    "position_of_match_inside_the_read=np.zeros(length_of_read) # initilize numpy array for position of match in the read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fbd4782",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PySAM' has no attribute 'AlignmentFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25836/3663534741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msamfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbam_file_to_read\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# read the indexed and sorted bam file using pysam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PySAM' has no attribute 'AlignmentFile'"
     ]
    }
   ],
   "source": [
    "samfile = pysam.AlignmentFile(bam_file_to_read,\"rb\") # read the indexed and sorted bam file using pysam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa5f202",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pysam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25836/2792238738.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### use pysam to examine all the reads aligned for each position of each transcipt and detect editing sites\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msamfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbam_file_to_read\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# read the indexed and sorted bam file using pysam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfile2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# file in which the detected editing sited will be listed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtranscript_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'comp141540_c0_seq3'\u001b[0m \u001b[1;31m# in case only one transcript is run ('comp141540_c0_seq3' is spectrin)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pysam' is not defined"
     ]
    }
   ],
   "source": [
    "### use pysam to examine all the reads aligned for each position of each transcipt and detect editing sites\n",
    "samfile = pysam.AlignmentFile(bam_file_to_read,\"rb\") # read the indexed and sorted bam file using pysam \n",
    "file2 = open(output_file,\"w\") # file in which the detected editing sited will be listed \n",
    "transcript_name='comp141540_c0_seq3' # in case only one transcript is run ('comp141540_c0_seq3' is spectrin)\n",
    "\n",
    "# run over all transcripts\n",
    "file2.write(\"\\nname of transcript = %s\\n\" % transcript_name) # list the current transcript\n",
    "# run over all positions of the transcript and fetch the reads aligned to it \n",
    "# only fetch reads that have the maximal mapping score (i.e. unique alignment)\n",
    "for pileupcolumn in samfile.pileup(transcript_name,min_mapping_quality=max_mapping_score): \n",
    "    position=pileupcolumn.pos\n",
    "    # initilize the dictionary counts_per_letter\n",
    "    type_of_letters=['A','C','G','T']\n",
    "    for x in type_of_letters:\n",
    "        counts_per_letter[x]=0\n",
    "    # run over all reads that align against the transcript in the given position\n",
    "    for pileupread in pileupcolumn.pileups:\n",
    "        # query position is None if is_del or is_refskip is set\n",
    "        if not pileupread.is_del and not pileupread.is_refskip:\n",
    "            # demand minimum quality score for the aligned base\n",
    "            if pileupread.alignment.query_qualities[pileupread.query_position]>=minimum_qaulity_score:\n",
    "                # detect the base\n",
    "                letter=pileupread.alignment.query_sequence[pileupread.query_position]\n",
    "                # count how many times each base was detected\n",
    "                counts_per_letter[letter]=counts_per_letter[letter]+1 \n",
    "    # sort the counts per base to detect the base most frequent and the second base i.e. the modification\n",
    "    sorted_dict = dict( sorted(counts_per_letter.items(),\n",
    "                               key=lambda item: item[1],\n",
    "                               reverse=True)) # sort descending\n",
    "    i=0 # a running number to detect the first and second most frequent bases\n",
    "    N=0 # total number of reads aligned to the first and second most frequent bases \n",
    "    for key, value in sorted_dict.items():\n",
    "        i=i+1 \n",
    "        if i==1:\n",
    "            N=N+value\n",
    "            first_letter=key # the most frequent base\n",
    "        elif i==2:\n",
    "            X=value # the number of times the modified base appeared\n",
    "            N=N+value\n",
    "            second_letter=key # the second most frequent base\n",
    "            modification=first_letter+second_letter # the modification, for example AG (i.e A changed to G)\n",
    "        else:\n",
    "            break\n",
    "    # given a rate of sequencing error P, total number of counts N, and modified counts X \\\n",
    "    #  the probability of event being a sequencing error is 1 - binomial_CDF(X-1,N,P) \\\n",
    "    #  this is the same as binomial_CDF(N-X,N,1-P) (but the latter is more accurate due to rounding errors) \n",
    "    prob = binom.cdf(N-X,N,1-P)  \n",
    "    # bonferroni correction p_cutoff divided by the overall number of tests\n",
    "    if prob<(p_cutoff/total_orf_size):\n",
    "        # print the total number of reads aligned for the specfic location inside the transcript\n",
    "        file2.write(\"\\ncoverage at base %s = %s\" % (pileupcolumn.pos, pileupcolumn.n))  \n",
    "        # sort the number of bases and print them to file\n",
    "        for key, value in sorted_dict.items():\n",
    "            file2.write('\\ncounts of base %s = %s' % (key,str(value)))\n",
    "        file2.write('\\nX is %s and N is %s' % (str(X),str(N))) # print X and N, as defined above\n",
    "        part1='\\nP-value for sequencing error is\\t' \n",
    "        part2=\"{:.2e}\".format(prob)\n",
    "        part3='\\n'\n",
    "        file2.write(part1+part2+part3) # print the P-value\n",
    "        # update the number of modifications\n",
    "        number_of_modifications[modification]=number_of_modifications[modification]+1\n",
    "        # check the location of the match and mismatch in the read \n",
    "        #  to estimate if the modifications came from the reads ends \n",
    "        # run over all reads that align against the transcript in the given position \n",
    "        for pileupread in pileupcolumn.pileups:\n",
    "            # query position is None if is_del or is_refskip is set\n",
    "            if not pileupread.is_del and not pileupread.is_refskip:\n",
    "                # demand minimum quality score for the aligned base\n",
    "                if pileupread.alignment.query_qualities[pileupread.query_position]>=minimum_qaulity_score:\n",
    "                    # detect the base\n",
    "                    letter=pileupread.alignment.query_sequence[pileupread.query_position]\n",
    "                    if (letter==first_letter): # these are reads that show the match\n",
    "                        position_of_match_inside_the_read[pileupread.query_position]=\\\n",
    "                        position_of_match_inside_the_read[pileupread.query_position]+1\n",
    "                    elif (letter==second_letter): # these are reads that show the mismatch\n",
    "                        position_of_mismatch_inside_the_read[pileupread.query_position]=\\\n",
    "                        position_of_mismatch_inside_the_read[pileupread.query_position]+1\n",
    "file2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('lamootHW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3566c55396aa67d6d450caee2c72072e0a80bcedc801748038b289e6d3e79506"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
